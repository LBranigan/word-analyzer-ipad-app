# Word Analyzer iPad App

An iPad app for teachers to assess student oral reading fluency. Students read a passage aloud while the app records audio and captures an image of the text. The backend uses AI to analyze the reading, producing detailed metrics, error pattern analysis, and personalized audio feedback.

## Features

- **Audio Recording** - Record students reading passages (30s or 60s duration)
- **Image Capture** - Take a photo of the reading passage for OCR
- **AI-Powered Analysis** - Google Cloud Speech-to-Text and Vision OCR
- **Word-by-Word Alignment** - Dynamic programming algorithm matches spoken to expected words
- **Comprehensive Metrics** - Accuracy %, Words Per Minute, Prosody Score (4-component weighted)
- **Error Pattern Detection** - Identifies consonant blend issues, digraph errors, first-letter guessing, etc.
- **AI Summary with Voice** - Personalized feedback generated by Gemini AI, spoken with Google Cloud TTS (Studio voices)
- **Video Generation** - Auto-generated video showing word-by-word highlighting synced to audio
- **PDF Reports** - Exportable assessment reports

## Screenshots

The app has 5 main screens:
1. **Home** - Student selection and assessment history
2. **Recording** - Audio capture with voice prompts
3. **Capture** - Image capture of reading passage
4. **Analysis** - Results with 5 tabs (Summary, Video, Export, Image, Patterns)
5. **History** - Past assessment review

## Tech Stack

- **Frontend**: React Native / Expo (iPad optimized)
- **Backend**: Firebase Cloud Functions (Node.js 20)
- **Database**: Cloud Firestore (real-time sync)
- **Storage**: Firebase Storage (24h TTL for media)
- **AI Services**:
  - Google Cloud Speech-to-Text (transcription)
  - Google Cloud Vision (OCR)
  - Google Gemini 1.5 Flash (AI summaries)
  - Google Cloud Text-to-Speech (Studio voices)

## Prerequisites

- Node.js 18+
- npm or yarn
- Firebase CLI (`npm install -g firebase-tools`)
- Expo CLI (`npm install -g expo-cli`)
- Google Cloud project with enabled APIs:
  - Cloud Speech-to-Text
  - Cloud Vision
  - Cloud Text-to-Speech
- Gemini API key (from [Google AI Studio](https://aistudio.google.com/apikey))

## Installation

### 1. Clone the repository

```bash
git clone https://github.com/LBranigan/word-analyzer-ipad-app.git
cd word-analyzer-ipad-app/word-analyzer-app
```

### 2. Install dependencies

```bash
# Frontend dependencies
npm install

# Backend dependencies
cd functions
npm install
cd ..
```

### 3. Firebase Setup

```bash
# Login to Firebase
firebase login

# Initialize Firebase (select your project)
firebase init
# Select: Firestore, Functions, Storage
```

### 4. Configure Firebase

Create `src/config/firebase.ts` with your Firebase config:

```typescript
import { initializeApp } from 'firebase/app';
import { getFirestore } from 'firebase/firestore';
import { getStorage } from 'firebase/storage';
import { getAuth } from 'firebase/auth';

const firebaseConfig = {
  apiKey: "YOUR_API_KEY",
  authDomain: "YOUR_PROJECT.firebaseapp.com",
  projectId: "YOUR_PROJECT_ID",
  storageBucket: "YOUR_PROJECT.appspot.com",
  messagingSenderId: "YOUR_SENDER_ID",
  appId: "YOUR_APP_ID"
};

const app = initializeApp(firebaseConfig);
export const db = getFirestore(app);
export const storage = getStorage(app);
export const auth = getAuth(app);
```

### 5. Set Firebase Secrets

```bash
# Required for AI summaries
firebase functions:secrets:set GEMINI_API_KEY
# Enter your Gemini API key when prompted
```

Note: Google Cloud TTS uses the default service account credentials (no separate API key needed).

### 6. Deploy Cloud Functions

```bash
cd functions
npm run deploy
```

### 7. Run the App

```bash
# For iPad testing via Expo Go
npx expo start --tunnel

# Scan QR code with iPad camera to open in Expo Go
```

## Project Structure

```
word-analyzer-app/
├── src/
│   ├── screens/
│   │   ├── HomeScreen.tsx          # Student selection
│   │   ├── RecordingScreen.tsx     # Audio recording with prompts
│   │   ├── CaptureScreen.tsx       # Image capture
│   │   ├── AnalysisScreen.tsx      # Results (5 tabs)
│   │   └── HistoryScreen.tsx       # Past assessments
│   ├── services/
│   │   ├── assessmentService.ts    # Firebase upload, subscriptions
│   │   └── studentService.ts       # Student CRUD
│   └── types/index.ts              # TypeScript interfaces
├── functions/
│   └── src/
│       ├── index.ts                # Cloud Function entry points
│       └── services/
│           ├── speechToText.ts     # Google Speech API
│           ├── visionOcr.ts        # Google Vision OCR
│           ├── wordMatching.ts     # DP alignment algorithm
│           ├── metricsCalculator.ts# Accuracy, WPM, prosody
│           ├── summaryGenerator.ts # Gemini AI summaries
│           ├── textToSpeech.ts     # Google Cloud TTS (Studio)
│           ├── videoGenerator.ts   # MP4 with highlights
│           └── pdfGenerator.ts     # PDF reports
├── docs/
│   └── analysis-concept-map.html   # Technical documentation
├── CLAUDE.md                       # Developer documentation
└── README.md                       # This file
```

## How It Works

### Analysis Pipeline

1. **Record** - Student reads passage aloud (30s/60s)
2. **Early Upload** - Audio uploads immediately while user takes picture
3. **Pre-Transcribe** - Background transcription starts for faster processing
4. **Capture** - User takes photo of reading passage
5. **Process** - OCR + Word Alignment + Metrics + AI Summary
6. **Results** - Real-time display with 5 interactive tabs

### Word Matching Algorithm

Uses dynamic programming to optimally align spoken words to expected text:
- Handles skipped words, substitutions, and insertions
- Phonetic equivalents (homophones) count as correct
- OCR confusion handling (machine errors don't penalize students)
- Number equivalents ("fifteen" = "15")

### Prosody Score (4 Components)

| Component | Weight | Measures |
|-----------|--------|----------|
| Accuracy | 35% | Percentage of words read correctly |
| Rate | 25% | Words per minute (optimal: 100-180) |
| Fluency | 25% | Error rate across reading |
| Smoothness | 15% | Hesitations + fillers + repeats |

### Error Pattern Analysis

Detects specific reading difficulties:
- Consonant blend issues (bl, tr, str)
- Digraph errors (ch, sh, th)
- First-letter guessing
- R/W substitution patterns
- Visual similarity confusion (b/d, p/q)

## Development

### TypeScript Check

```bash
# Frontend
npx tsc --noEmit

# Backend
cd functions && npx tsc --noEmit
```

### Deploy Functions

```bash
cd functions
npm run deploy
```

### View Function Logs

```bash
firebase functions:log
```

## Documentation

- **CLAUDE.md** - Developer documentation with detailed API reference
- **docs/analysis-concept-map.html** - Visual technical documentation (open in browser)

## Privacy & Compliance

This app processes student data through cloud services:
- **Google Cloud** services are used for Speech-to-Text, Vision OCR, and Text-to-Speech
- Schools should have a Google Cloud DPA (Data Processing Agreement) in place for FERPA compliance
- Student names and performance data are sent to AI services for personalized feedback generation

## Known Limitations

1. **Web Camera** - Safari WebRTC defaults to 640x480, affecting OCR quality. Use Expo Go for native resolution.
2. **Transcription Time** - 30-60 seconds for long recordings (Google API limitation)

## License

MIT

## Contributing

Pull requests welcome! Please read the developer documentation in CLAUDE.md first.
